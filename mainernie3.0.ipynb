{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9608cd-5a61-432a-bb9f-cd8e11d4ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/paddle1/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "WARNING: OMP_NUM_THREADS set to 16, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.\n",
      "PLEASE USE OMP_NUM_THREADS WISELY.\n",
      "/root/miniconda3/envs/paddle1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/paddle1/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "W0613 05:41:04.450403 13607 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.8, Runtime API Version: 11.8\n",
      "W0613 05:41:04.451148 13607 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading cached features from cache_features/train_features_cached.pkl\n",
      "[INFO] Loading cached features from cache_features/val_features_cached.pkl\n",
      "[INFO] Loading cached features from cache_features/test_features_cached.pkl\n",
      "train_dataset total samples: 11184\n",
      "val_dataset total samples: 1309\n",
      "test_dataset total samples: 1129\n",
      "({'qImg_feature': array([5.0892222e-01, 1.0130705e-01, 4.1554770e-01, ..., 1.5136348e-01,\n",
      "       7.5677846e-05, 2.2541411e-01], dtype=float32), 'qCap': '看到有人说 这老头说了句话 不是我退休了 要是没退休 你早就在牢里了 说是某地政法系统的前领导 正局级干部退休的 我想问这种人敢说出这种话 在职间到底', 'imgs_features': [array([0.6166205 , 0.32743877, 0.23644671, ..., 0.6098976 , 0.32837993,\n",
      "       0.09397861], dtype=float32), array([0.23688133, 0.73640347, 0.12396187, ..., 0.24109195, 0.10670266,\n",
      "       0.16786775], dtype=float32), array([0.30910894, 0.14095385, 0.31212616, ..., 0.0553519 , 0.00824548,\n",
      "       0.04955674], dtype=float32)], 'caption': ['Boston Orange  波士頓菊子: 朱学渊  - 為中國史學的實證化而努力', '新华每日电讯-微报纸-2021年11月19日', '新华每日电讯-微报纸-2022年01月28日']}, 3, 3)\n",
      "[Tensor(shape=[1], dtype=int64, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [0]), [['Sixth Memphis officer fired after Tyre Nichols  death - NBC News', 'The Memphis Police Department fired Preston Hemphill after a review determined he violated multiple department policies.', 'After the beating death of Tyre Nichols, a 6th Memphis officer has been fired : NPR', 'Protesters march Saturday, Jan. 28, in Memphis, Tenn., over the death of Tyre Nichols, who died after being beaten by Memphis police.', \"Tyre Nichols: Another Memphis police officer terminated, two first responders suspended in the wake of Tyre Nichols' death | CNN\", 'A sixth Memphis Police officer involved in the arrest which led to the death of Tyre Nichols on Jan. 7 has been relieved of duty.', 'Memphis Police officers terminated after deadly traffic stop in Memphis', 'Memphis Police Department', 'Memphis Police Officer Preston Hemphill.', \"Sixth Memphis officer fired after Tyre Nichols' death\", \"Memphis police fire another officer in Tyre Nichols' death | Reuters\", 'Sixth officer involved in Tyre Nichols death relieved of duty | localmemphis.com']], Tensor(shape=[1, 5, 2048], dtype=float32, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [[[0.48245648, 0.22957455, 0.24084565, ..., 1.12753558,\n",
      "          0.38714987, 0.53717303],\n",
      "         [0.08478894, 0.15969926, 0.53607243, ..., 0.96418381,\n",
      "          0.03903590, 0.26742047],\n",
      "         [0.10093364, 0.42440569, 0.20196082, ..., 0.70122278,\n",
      "          0.02389923, 0.48772454],\n",
      "         [0.18447548, 0.37096509, 0.10779488, ..., 1.32890546,\n",
      "          0.00533395, 0.65301162],\n",
      "         [0.46931082, 0.22600143, 0.25980654, ..., 1.15869212,\n",
      "          0.41738480, 0.56481397]]]), ['A sixth Memphis police officer has been fired after the death of Tyre Nichols,'], Tensor(shape=[1, 2048], dtype=float32, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [[0.10992016, 0.05876775, 0.80977678, ..., 0.28487116, 0.05753119,\n",
      "         0.07121076]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-06-13 05:41:08,284] [    INFO]\u001b[0m - Loading weights file from cache at /root/.paddlenlp/models/ernie-3.0-base-zh/model_state.pdparams\u001b[0m\n",
      "\u001b[32m[2025-06-13 05:41:08,782] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[33m[2025-06-13 05:41:09,284] [ WARNING]\u001b[0m - Some weights of the model checkpoint at ernie-3.0-base-zh were not used when initializing ErnieModel: ['cls.predictions.decoder_bias', 'cls.predictions.layer_norm.bias', 'cls.predictions.layer_norm.weight', 'cls.predictions.transform.bias', 'cls.predictions.transform.weight']\n",
      "- This IS expected if you are initializing ErnieModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ErnieModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[32m[2025-06-13 05:41:09,285] [    INFO]\u001b[0m - All the weights of ErnieModel were initialized from the model checkpoint at ernie-3.0-base-zh.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ErnieModel for predictions without further training.\u001b[0m\n",
      "\u001b[32m[2025-06-13 05:41:09,325] [    INFO]\u001b[0m - tokenizer config file saved in /root/.paddlenlp/models/ernie-3.0-base-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2025-06-13 05:41:09,327] [    INFO]\u001b[0m - Special tokens file saved in /root/.paddlenlp/models/ernie-3.0-base-zh/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111840 11184\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/11184 [00:00<?, ?it/s]W0613 05:41:09.703253 13607 gpu_resources.cc:306] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\n",
      "Training Epoch 1: 100%|█████████▉| 11182/11184 [09:00<00:00, 21.73it/s, loss=0.2472, acc=0.6457, step=11184]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.48996, acc: 0.82124, f1: 0.76360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 11184/11184 [09:15<00:00, 20.12it/s, loss=0.2472, acc=0.6457, step=11184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 11184 | F1: 0.7636 (updated)\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|█████████▉| 11182/11184 [09:04<00:00, 19.17it/s, loss=0.0025, acc=0.8552, step=22368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.29391, acc: 0.89152, f1: 0.86573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 11184/11184 [09:18<00:00,  3.60s/it, loss=0.0025, acc=0.8552, step=22368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 22368 | F1: 0.8657 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 11184/11184 [09:19<00:00, 20.00it/s, loss=0.0025, acc=0.8552, step=22368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|█████████▉| 11183/11184 [09:05<00:00, 22.42it/s, loss=0.1175, acc=0.9017, step=33552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.22231, acc: 0.91902, f1: 0.90413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 11184/11184 [09:16<00:00,  3.44s/it, loss=0.1175, acc=0.9017, step=33552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 33552 | F1: 0.9041 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 11184/11184 [09:17<00:00, 20.08it/s, loss=0.1175, acc=0.9017, step=33552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|█████████▉| 11181/11184 [08:58<00:00, 23.43it/s, loss=0.0056, acc=0.9274, step=44736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.19772, acc: 0.92666, f1: 0.91293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 11184/11184 [09:13<00:00,  2.75s/it, loss=0.0056, acc=0.9274, step=44736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 44736 | F1: 0.9129 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 11184/11184 [09:14<00:00, 20.17it/s, loss=0.0056, acc=0.9274, step=44736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|█████████▉| 11181/11184 [09:03<00:00, 20.32it/s, loss=0.4741, acc=0.9402, step=55920]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.18583, acc: 0.93354, f1: 0.92469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 11184/11184 [09:15<00:00,  2.82s/it, loss=0.4741, acc=0.9402, step=55920]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 55920 | F1: 0.9247 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 11184/11184 [09:16<00:00, 20.10it/s, loss=0.4741, acc=0.9402, step=55920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|█████████▉| 11181/11184 [09:07<00:00, 21.76it/s, loss=0.0458, acc=0.9481, step=67104]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.16229, acc: 0.94500, f1: 0.93720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 11184/11184 [09:17<00:00,  3.11s/it, loss=0.0458, acc=0.9481, step=67104]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 67104 | F1: 0.9372 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 11184/11184 [09:18<00:00, 20.01it/s, loss=0.0458, acc=0.9481, step=67104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 11184/11184 [09:16<00:00,  3.22s/it, loss=0.0374, acc=0.9598, step=78288]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.18896, acc: 0.93583, f1: 0.92362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 11184/11184 [09:17<00:00, 20.05it/s, loss=0.0374, acc=0.9598, step=78288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 11184/11184 [09:17<00:00,  3.12s/it, loss=0.1249, acc=0.9625, step=89472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.18809, acc: 0.93965, f1: 0.92678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 11184/11184 [09:19<00:00, 20.00it/s, loss=0.1249, acc=0.9625, step=89472]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 11184/11184 [09:13<00:00,  3.33s/it, loss=0.0001, acc=0.9650, step=100656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.18252, acc: 0.94118, f1: 0.93008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 11184/11184 [09:15<00:00, 20.13it/s, loss=0.0001, acc=0.9650, step=100656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 11184/11184 [09:17<00:00,  2.97s/it, loss=0.0000, acc=0.9687, step=111840]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.17092, acc: 0.94347, f1: 0.93288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 11184/11184 [09:19<00:00, 19.98it/s, loss=0.0000, acc=0.9687, step=111840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1129/1129 [00:29<00:00, 37.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "import gc\n",
    "import paddle\n",
    "from paddlenlp.datasets import load_dataset\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as nn\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "import pandas as pd\n",
    "from paddle.vision import transforms as T\n",
    "from paddle.io import Dataset\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image\n",
    "import os\n",
    "import imghdr\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 更通用的写法，兼容 Jupyter 和脚本运行\n",
    "try:\n",
    "    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "except NameError:\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "dataset_dir = os.path.join(base_dir, 'autodl-tmp/queries_dataset_merge')\n",
    "\n",
    "paddle.set_device('gpu')  # 如果没 GPU，可以改为 'cpu'\n",
    "\n",
    "#读取数据\n",
    "import json\n",
    "data_items_train = json.load(open(os.path.join(dataset_dir, 'dataset_items_train.json'), encoding='utf-8'))\n",
    "data_items_val = json.load(open(os.path.join(dataset_dir, 'dataset_items_val.json'), encoding='utf-8'))\n",
    "data_items_test = json.load(open(os.path.join(dataset_dir, 'dataset_items_test.json'), encoding='utf-8'))\n",
    "\n",
    "\n",
    "#读取数据中的每一个样本：图像img、文本caption、\n",
    "#对应的img_html_news、inverse_search为支持图像img和文本caption的证据材料\n",
    "def process_string(input_str):\n",
    "    input_str = input_str.replace('&#39;', ' ')\n",
    "    input_str = input_str.replace('<b>', '')\n",
    "    input_str = input_str.replace('</b>', '')\n",
    "    # input_str = unidecode(input_str)\n",
    "    return input_str\n",
    "\n",
    "\n",
    "class FeatureCachedNewsContextDataset(Dataset):\n",
    "    def __init__(self, context_data_items_dict, queries_root_dir, split, resnet_model, cache_dir='cache_features'):\n",
    "        self.cache_path = os.path.join(cache_dir, f'{split}_features_cached.pkl')\n",
    "        self.split = split\n",
    "        self.resnet = resnet_model\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(self.cache_path):\n",
    "            print(f\"[INFO] Loading cached features from {self.cache_path}\")\n",
    "            with open(self.cache_path, 'rb') as f:\n",
    "                self.samples = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"[INFO] Creating cache with CNN features for {split} set...\")\n",
    "            self.samples = self.preprocess_and_cache(context_data_items_dict, queries_root_dir)\n",
    "            with open(self.cache_path, 'wb') as f:\n",
    "                pickle.dump(self.samples, f)\n",
    "            print(f\"[INFO] Cached features saved to {self.cache_path}\")\n",
    "\n",
    "    def preprocess_and_cache(self, data_dict, queries_root_dir):\n",
    "        from PIL import Image\n",
    "        import imghdr\n",
    "        from paddle.vision import transforms as T\n",
    "\n",
    "        transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        def load_image(image_path):\n",
    "            try:\n",
    "                if imghdr.what(image_path) == 'gif':\n",
    "                    with open(image_path, 'rb') as f:\n",
    "                        img = Image.open(f).convert('RGB')\n",
    "                else:\n",
    "                    with open(image_path, 'rb') as f:\n",
    "                        img = Image.open(f).convert('RGB')\n",
    "                return transform(img)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        def process_string(text):\n",
    "            return text.replace('&#39;', ' ').replace('<b>', '').replace('</b>', '')\n",
    "\n",
    "        def extract_captions(inv_dict, direct_dict):\n",
    "            captions = []\n",
    "            for key in ['all_fully_matched_captions', 'all_partially_matched_captions']:\n",
    "                for page in inv_dict.get(key, []):\n",
    "                    if 'title' in page:\n",
    "                        captions.append(process_string(page['title']))\n",
    "                    if 'caption' in page:\n",
    "                        for val in page['caption'].values():\n",
    "                            captions.append(process_string(val))\n",
    "            for key in ['images_with_captions', 'images_with_caption_matched_tags', 'images_with_no_captions']:\n",
    "                for page in direct_dict.get(key, []):\n",
    "                    if 'page_title' in page:\n",
    "                        captions.append(process_string(page['page_title']))\n",
    "                    if 'caption' in page:\n",
    "                        for val in page['caption'].values():\n",
    "                            captions.append(process_string(val))\n",
    "            return list(set(captions))\n",
    "\n",
    "        MAX_IMG_PER_SAMPLE = 100\n",
    "        samples = []\n",
    "\n",
    "        for key in tqdm(data_dict, desc=f\"Processing {self.split} with features\"):\n",
    "            item = data_dict[key]\n",
    "            try:\n",
    "                qimg_path = os.path.join(queries_root_dir, item['image_path'])\n",
    "                qimg_tensor = load_image(qimg_path)\n",
    "                if qimg_tensor is None:\n",
    "                    continue\n",
    "                qImg_feature = self.resnet(qimg_tensor.unsqueeze(0)).detach().cpu().squeeze(0).numpy()\n",
    "\n",
    "                direct_path = os.path.join(queries_root_dir, item['direct_path'])\n",
    "                inverse_path = os.path.join(queries_root_dir, item['inv_path'])\n",
    "\n",
    "                with open(os.path.join(direct_path, 'direct_annotation.json'), encoding='utf-8') as f:\n",
    "                    direct_dict = json.load(f)\n",
    "                with open(os.path.join(inverse_path, 'inverse_annotation.json'), encoding='utf-8') as f:\n",
    "                    inv_dict = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {e}, skipping {key}\")\n",
    "                continue\n",
    "\n",
    "            evidence_features = []\n",
    "            for key1 in ['images_with_captions', 'images_with_no_captions', 'images_with_caption_matched_tags']:\n",
    "                pages = direct_dict.get(key1, [])\n",
    "                for i, page in enumerate(pages):\n",
    "                    if i >= MAX_IMG_PER_SAMPLE:\n",
    "                        break\n",
    "                    img_path = os.path.join(direct_path, page['image_path'].split('/')[-1])\n",
    "                    img_tensor = load_image(img_path)\n",
    "                    if img_tensor is not None:\n",
    "                        img_feature = self.resnet(img_tensor.unsqueeze(0)).detach().cpu().squeeze(0).numpy()\n",
    "                        evidence_features.append(img_feature)\n",
    "\n",
    "            if len(evidence_features) == 0:\n",
    "                continue\n",
    "\n",
    "            captions = extract_captions(inv_dict, direct_dict)\n",
    "            sample = {\n",
    "                'qImg_feature': qImg_feature,\n",
    "                'qCap': item['caption'],\n",
    "                'imgs_features': evidence_features,\n",
    "                'caption': captions\n",
    "            }\n",
    "            if self.split != 'test':\n",
    "                sample['label'] = int(item['label'])\n",
    "\n",
    "            samples.append(sample)\n",
    "\n",
    "            # 显存清理\n",
    "            del qImg_feature, evidence_features, img_tensor, qimg_tensor\n",
    "            gc.collect()\n",
    "            paddle.device.cuda.empty_cache()\n",
    "\n",
    "        print(f\"[INFO] Cached {len(samples)} samples for {self.split}\")\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        if self.split != 'test':\n",
    "            return sample, len(sample['caption']), len(sample['imgs_features'])\n",
    "        else:\n",
    "            return sample, len(sample['caption']), len(sample['imgs_features'])\n",
    "\n",
    "from paddle.vision import models\n",
    "from paddle import nn\n",
    "import paddle\n",
    "class EncoderCNN(nn.Layer):\n",
    "    def __init__(self, resnet_arch='resnet101'):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        if resnet_arch == 'resnet101':\n",
    "            resnet = models.resnet101(pretrained=True)\n",
    "        elif resnet_arch == 'resnet50':\n",
    "            resnet = models.resnet50(pretrained=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported ResNet arch: {resnet_arch}\")\n",
    "\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2D((1, 1))\n",
    "\n",
    "    def forward(self, images, features='pool'):\n",
    "        out = self.resnet(images)\n",
    "        if features == 'pool':\n",
    "            out = self.adaptive_pool(out)\n",
    "            out = paddle.reshape(out, (out.shape[0], out.shape[1]))\n",
    "        return out\n",
    "\n",
    "#### load Datasets ####\n",
    "resnet = EncoderCNN(resnet_arch='resnet50')\n",
    "resnet.eval()\n",
    "train_dataset = FeatureCachedNewsContextDataset(data_items_train, dataset_dir, 'train', resnet)\n",
    "val_dataset = FeatureCachedNewsContextDataset(data_items_val, dataset_dir, 'val', resnet)\n",
    "test_dataset = FeatureCachedNewsContextDataset(data_items_test, dataset_dir, 'test', resnet)\n",
    "print(f\"train_dataset total samples: {len(train_dataset)}\")\n",
    "print(f\"val_dataset total samples: {len(val_dataset)}\")\n",
    "print(f\"test_dataset total samples: {len(test_dataset)}\")\n",
    "\n",
    "# 打印数据\n",
    "for step, batch in enumerate(test_dataset, start=1):\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "def collate_context_cached_train(batch):\n",
    "    samples = [item[0] for item in batch]\n",
    "    max_caps = max([item[1] for item in batch])\n",
    "    max_imgs = max([item[2] for item in batch])\n",
    "\n",
    "    qCap_batch, qImg_feature_batch, caps_batch, imgs_feature_batch, labels = [], [], [], [], []\n",
    "\n",
    "    for sample in samples:\n",
    "        caps = sample['caption'] + [\"\"] * (max_caps - len(sample['caption']))\n",
    "        caps_batch.append(caps)\n",
    "\n",
    "        imgs = sample['imgs_features']\n",
    "        imgs = [paddle.to_tensor(img, dtype='float32') for img in imgs]\n",
    "        pad = [paddle.zeros_like(imgs[0]) for _ in range(max_imgs - len(imgs))]\n",
    "        imgs_padded = imgs + pad\n",
    "        imgs_feature_batch.append(paddle.stack(imgs_padded))\n",
    "\n",
    "        qCap_batch.append(sample['qCap'])\n",
    "        qImg_feature_batch.append(paddle.to_tensor(sample['qImg_feature'], dtype='float32'))\n",
    "\n",
    "        labels.append(paddle.to_tensor(sample['label']))\n",
    "\n",
    "    qImg_feature_batch = paddle.stack(qImg_feature_batch, axis=0)\n",
    "    imgs_feature_batch = paddle.stack(imgs_feature_batch, axis=0)\n",
    "    labels = paddle.stack(labels)\n",
    "\n",
    "    return labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch\n",
    "\n",
    "\n",
    "def collate_context_cached_test(batch):\n",
    "    samples = [item[0] for item in batch]\n",
    "    max_caps = max([item[1] for item in batch])\n",
    "    max_imgs = max([item[2] for item in batch])\n",
    "\n",
    "    qCap_batch, qImg_feature_batch, caps_batch, imgs_feature_batch = [], [], [], []\n",
    "\n",
    "    for sample in samples:\n",
    "        caps = sample['caption'] + [\"\"] * (max_caps - len(sample['caption']))\n",
    "        caps_batch.append(caps)\n",
    "\n",
    "        imgs = sample['imgs_features']\n",
    "        imgs = [paddle.to_tensor(img, dtype='float32') for img in imgs]\n",
    "        pad = [paddle.zeros_like(imgs[0]) for _ in range(max_imgs - len(imgs))]\n",
    "        imgs_padded = imgs + pad\n",
    "        imgs_feature_batch.append(paddle.stack(imgs_padded))\n",
    "\n",
    "        qCap_batch.append(sample['qCap'])\n",
    "        qImg_feature_batch.append(paddle.to_tensor(sample['qImg_feature'], dtype='float32'))\n",
    "\n",
    "    qImg_feature_batch = paddle.stack(qImg_feature_batch, axis=0)\n",
    "    imgs_feature_batch = paddle.stack(imgs_feature_batch, axis=0)\n",
    "\n",
    "    return caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch\n",
    "\n",
    "\n",
    "\n",
    "# load DataLoader\n",
    "from paddle.io import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True,\n",
    "                              collate_fn=collate_context_cached_train, return_list=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False,\n",
    "                            collate_fn=collate_context_cached_train, return_list=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                             collate_fn=collate_context_cached_test, return_list=True, num_workers=2)\n",
    "\n",
    "# 打印数据\n",
    "for step, batch in enumerate(train_dataloader, start=1):\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "#模型构建\n",
    "from paddle.vision import models\n",
    "import paddle\n",
    "from paddlenlp.transformers import ErnieModel, ErnieTokenizer\n",
    "from paddle.nn import functional as F\n",
    "from paddle import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "class EncoderCNN(nn.Layer):\n",
    "    def __init__(self, resnet_arch = 'resnet101'):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        if resnet_arch == 'resnet101':\n",
    "            resnet = models.resnet101(pretrained=True)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2D((1, 1))\n",
    "    def forward(self, images, features='pool'):\n",
    "        out = self.resnet(images)\n",
    "        if features == 'pool':\n",
    "            out = self.adaptive_pool(out)\n",
    "            out = paddle.reshape(out, (out.shape[0],out.shape[1]))\n",
    "        return out\n",
    "\n",
    "\n",
    "class NetWork(nn.Layer):\n",
    "    def __init__(self, mode):\n",
    "        super(NetWork, self).__init__()\n",
    "        self.mode = mode\n",
    "        # 把原来的 ErnieMModel 改成 ErnieModel\n",
    "        self.ernie = ErnieModel.from_pretrained('ernie-3.0-base-zh')\n",
    "        self.tokenizer = ErnieTokenizer.from_pretrained('ernie-3.0-base-zh')\n",
    "        self.attention_text = nn.MultiHeadAttention(embed_dim=768, num_heads=16)\n",
    "        self.attention_image = nn.MultiHeadAttention(embed_dim=2048, num_heads=16)\n",
    "\n",
    "        if self.mode == 'text':\n",
    "            self.classifier = nn.Linear(768, 3)\n",
    "        else:\n",
    "            self.classifier1 = nn.Linear(2 * (768 + 2048), 1024)\n",
    "            self.classifier2 = nn.Linear(1024, 3)\n",
    "\n",
    "    def forward(self, qCap, qImg_feature, caps, imgs_features):\n",
    "        # Encode qCap\n",
    "        encode_dict_qcap = self.tokenizer(text=qCap, max_length=128, truncation=True, padding='max_length')\n",
    "        input_ids_qcap = paddle.to_tensor(encode_dict_qcap['input_ids'])\n",
    "        qcap_feature, _ = self.ernie(input_ids_qcap)\n",
    "\n",
    "        if self.mode == 'text':\n",
    "            logits = self.classifier(qcap_feature[:, 0, :])\n",
    "            return logits\n",
    "\n",
    "        # Encode all evidence captions\n",
    "        caps_feature = []\n",
    "        for caption_list in caps:\n",
    "            encode_dict_cap = self.tokenizer(text=caption_list, max_length=128, truncation=True, padding='max_length')\n",
    "            input_ids_caps = paddle.to_tensor(encode_dict_cap['input_ids'])\n",
    "            cap_feature, _ = self.ernie(input_ids_caps)\n",
    "            cap_feature = cap_feature.mean(axis=1)  # mean pooling over all captions\n",
    "            caps_feature.append(cap_feature)\n",
    "        caps_feature = paddle.stack(caps_feature, axis=0)\n",
    "\n",
    "        # Attention between qcap and caps\n",
    "        caps_feature = self.attention_text(qcap_feature, caps_feature, caps_feature)\n",
    "\n",
    "        # Attention over image features\n",
    "        # imgs_features = paddle.stack(imgs_features, axis=0)  # [B, N, 2048]\n",
    "        qImg_feature = qImg_feature.unsqueeze(1)  # [B, 1, 2048]\n",
    "        imgs_features = self.attention_image(qImg_feature, imgs_features, imgs_features)\n",
    "\n",
    "        # Concatenate and classify\n",
    "        feature = paddle.concat(\n",
    "            [qcap_feature[:, 0, :], caps_feature[:, 0, :], qImg_feature.squeeze(1), imgs_features.squeeze(1)],\n",
    "            axis=-1)\n",
    "        logits = self.classifier1(feature)\n",
    "        logits = self.classifier2(logits)\n",
    "        return logits\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "        logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                       caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        preds = paddle.argmax(F.softmax(logits, axis=-1), axis=1)\n",
    "        all_preds.extend(preds.numpy().tolist())\n",
    "        all_labels.extend(labels.numpy().tolist())\n",
    "\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "\n",
    "    acc = metric.accumulate()\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')  # 或 'weighted' 视情况而定\n",
    "    print(f\"Eval loss: {np.mean(losses):.5f}, acc: {acc:.5f}, f1: {f1:.5f}\")\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return np.mean(losses), acc, f1\n",
    "\n",
    "\n",
    "# 声明模型\n",
    "model = NetWork(\"image\")\n",
    "#print(model)\n",
    "\n",
    "epochs = 10\n",
    "num_training_steps = len(train_dataloader) * epochs\n",
    "warmup_steps = int(num_training_steps*0.1)\n",
    "print(num_training_steps,warmup_steps)\n",
    "\n",
    "# 定义 learning_rate_scheduler，负责在训练过程中对 lr 进行调度\n",
    "lr_scheduler = LinearDecayWithWarmup(1e-6, num_training_steps, warmup_steps)\n",
    "# 训练结束后，存储模型参数\n",
    "save_dir =\"checkpoint/\"\n",
    "best_dir = \"best_model\"\n",
    "# 创建保存的文件夹\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "os.makedirs(best_dir,exist_ok=True)\n",
    "\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 定义 Optimizer\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=1.2e-4,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "# 交叉熵损失\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "# 评估的时候采用准确率指标\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "if paddle.is_compiled_with_cuda():\n",
    "    paddle.set_device('gpu')\n",
    "else:\n",
    "    paddle.set_device('cpu')\n",
    "\n",
    "# 定义训练\n",
    "def do_train(model, criterion, metric, val_dataloader, train_dataloader, optimizer, lr_scheduler,\n",
    "             save_dir=\"checkpoint\", best_dir=\"best_model\", epochs=10):\n",
    "\n",
    "    global_step = 0\n",
    "    best_f1 = 0.0\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(best_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        model.train()\n",
    "        train_loader_progress = tqdm(train_dataloader, desc=f\"Training Epoch {epoch}\", leave=True)\n",
    "\n",
    "        for step, batch in enumerate(train_loader_progress, start=1):\n",
    "            labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "\n",
    "            logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                           caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            correct = metric.compute(logits, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "\n",
    "            global_step += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            train_loader_progress.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"acc\": f\"{acc:.4f}\",\n",
    "                \"step\": global_step\n",
    "            })\n",
    "\n",
    "            if global_step % len(train_dataloader) == 0:\n",
    "                eval_loss, eval_acc, eval_f1 = evaluate(model, criterion, metric, val_dataloader)\n",
    "\n",
    "                if eval_f1 > best_f1:\n",
    "                    best_f1 = eval_f1\n",
    "                    best_model_path = os.path.join(best_dir, 'model_best3.pdparams')\n",
    "                    paddle.save(model.state_dict(), best_model_path)\n",
    "                    print(f\"[BEST] Step {global_step} | F1: {eval_f1:.4f} (updated)\")\n",
    "\n",
    "\n",
    "do_train(\n",
    "    model, criterion, metric, val_dataloader, train_dataloader,\n",
    "    optimizer, lr_scheduler,\n",
    "    save_dir=\"checkpoint\", best_dir=\"best_model\", epochs=10\n",
    ")\n",
    "\n",
    "\n",
    "# 根据实际运行情况，更换加载的参数路径\n",
    "import os\n",
    "import paddle\n",
    "\n",
    "# 加载最优模型\n",
    "params_path = os.path.join(\"best_model\", \"model_best3.pdparams\")\n",
    "if os.path.exists(params_path):\n",
    "    model.set_dict(paddle.load(params_path))\n",
    "    print(\"Loaded best model.\")\n",
    "\n",
    "model.eval()\n",
    "results = []\n",
    "for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n",
    "    caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "    logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                   caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "    preds = paddle.argmax(F.softmax(logits, axis=-1), axis=1).numpy()\n",
    "    results.extend(preds.tolist())\n",
    "\n",
    "# 保存\n",
    "pd.DataFrame({\"id\": range(len(results)), \"label\": results}).to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15c3c05-9e8c-486f-a076-0ff2e710529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1309/1309 [03:00<00:00,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.16229, Accuracy: 0.94500, F1 Score (macro): 0.93720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 验证函数（带F1）\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "        labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "        logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                       caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        preds = paddle.argmax(F.softmax(logits, axis=-1), axis=1)\n",
    "        all_preds.extend(preds.numpy().tolist())\n",
    "        all_labels.extend(labels.numpy().tolist())\n",
    "\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "\n",
    "        gc.collect()\n",
    "        paddle.device.cuda.empty_cache()\n",
    "\n",
    "    acc = metric.accumulate()\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(\"Eval Loss: {:.5f}, Accuracy: {:.5f}, F1 Score (macro): {:.5f}\".format(np.mean(losses), acc, f1))\n",
    "    return np.mean(losses), acc, f1\n",
    "\n",
    "# 加载模型参数\n",
    "params_path = os.path.join(\"best_model\", \"model_best3.pdparams\")\n",
    "if os.path.exists(params_path):\n",
    "    model.set_dict(paddle.load(params_path))\n",
    "    print(\"Loaded best model.\")\n",
    "else:\n",
    "    print(\"Best model file not found!\")\n",
    "\n",
    "# 损失函数和评估指标\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "# 执行评估\n",
    "eval_loss, eval_acc, eval_f1 = evaluate(model, criterion, metric, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11677d-1d31-43ea-ab2c-2cee0799d0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle1",
   "language": "python",
   "name": "paddle1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
