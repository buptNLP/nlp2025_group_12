{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9608cd-5a61-432a-bb9f-cd8e11d4ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/paddle1/lib/python3.12/site-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "WARNING: OMP_NUM_THREADS set to 16, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.\n",
      "PLEASE USE OMP_NUM_THREADS WISELY.\n",
      "/root/miniconda3/envs/paddle1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_3572/4164555512.py:23: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n",
      "W0603 15:12:34.969905  3572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.9, Driver API Version: 12.4, Runtime API Version: 11.8\n",
      "W0603 15:12:34.970671  3572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading cached features from cache_features/train_features_cached.pkl\n",
      "[INFO] Loading cached features from cache_features/val_features_cached.pkl\n",
      "[INFO] Loading cached features from cache_features/test_features_cached.pkl\n",
      "train_dataset total samples: 11184\n",
      "val_dataset total samples: 1309\n",
      "test_dataset total samples: 1129\n",
      "({'qImg_feature': array([5.0892222e-01, 1.0130705e-01, 4.1554770e-01, ..., 1.5136348e-01,\n",
      "       7.5677846e-05, 2.2541411e-01], dtype=float32), 'qCap': '看到有人说 这老头说了句话 不是我退休了 要是没退休 你早就在牢里了 说是某地政法系统的前领导 正局级干部退休的 我想问这种人敢说出这种话 在职间到底', 'imgs_features': [array([0.6166205 , 0.32743877, 0.23644671, ..., 0.6098976 , 0.32837993,\n",
      "       0.09397861], dtype=float32), array([0.23688133, 0.73640347, 0.12396187, ..., 0.24109195, 0.10670266,\n",
      "       0.16786775], dtype=float32), array([0.30910894, 0.14095385, 0.31212616, ..., 0.0553519 , 0.00824548,\n",
      "       0.04955674], dtype=float32)], 'caption': ['Boston Orange  波士頓菊子: 朱学渊  - 為中國史學的實證化而努力', '新华每日电讯-微报纸-2021年11月19日', '新华每日电讯-微报纸-2022年01月28日']}, 3, 3)\n",
      "[Tensor(shape=[2], dtype=int64, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [2, 2]), [['男子在马路中间躺下，哭着求民警拘留，背后原因让人哭笑不得 - 知乎', '妈妈向前冲冲冲_百度百科', '', ''], ['周深 Zhou Shen-Latest zhou shen songs-《50首你沒聽過的歌》 Best Songs Of Zhou Shen⏩起风了\\\\My Only\\\\请笃信一个梦\\\\大鱼\\\\悬崖之上 - YouTube', '【周深 Zhou Shen】【無廣告】周深好聽的48首歌,周深 2022 Best Songs Of Zhou Shen⏩《悬崖之上》《明月传说》《无所畏惧》《起风了》《归处》 - YouTube', '感谢Jack的耐心、专业和认真，感谢贵店的高效率和周全服务。本次订制了 ...', 'on Twitter: \"🦁️：1ke，什么是脏话？ ✒️：你在澳大利亚的寒冬和我 ...']], Tensor(shape=[2, 4, 2048], dtype=float32, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [[[0.02148909, 0.18088770, 0.13741083, ..., 0.77582830,\n",
      "          0.40872678, 0.97752249],\n",
      "         [0.20685357, 0.44522163, 0.50393158, ..., 0.19703768,\n",
      "          0.05795195, 1.85520887],\n",
      "         [0.14578107, 0.42437994, 0.50685716, ..., 0.20471032,\n",
      "          0.07071288, 1.97790229],\n",
      "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
      "          0.        , 0.        ]],\n",
      "\n",
      "        [[0.15089634, 0.29504406, 0.01835409, ..., 0.54886931,\n",
      "          0.29601479, 0.38991922],\n",
      "         [0.41303921, 0.10840853, 0.23862442, ..., 0.13090843,\n",
      "          0.00549662, 0.38355783],\n",
      "         [0.08522636, 0.00461070, 0.55430305, ..., 0.        ,\n",
      "          0.05064519, 1.06507289],\n",
      "         [0.98064590, 0.14780159, 0.52477348, ..., 0.46662891,\n",
      "          0.16661754, 0.52890837]]]), ['突然间觉得自己看错人了 昆山市', '好大我说的衬衣'], Tensor(shape=[2, 2048], dtype=float32, place=Place(gpu_pinned), stop_gradient=True,\n",
      "       [[0.43999410, 0.10849334, 0.17837226, ..., 0.00874511, 0.01126958,\n",
      "         0.11103763],\n",
      "        [0.24572070, 0.04100119, 0.00570051, ..., 0.40616715, 0.42247838,\n",
      "         0.78279054]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2025-06-03 15:12:38,738] [    INFO]\u001b[0m - Loading weights file from cache at /root/.paddlenlp/models/ernie-m-base/model_state.pdparams\u001b[0m\n",
      "\u001b[32m[2025-06-03 15:12:40,179] [    INFO]\u001b[0m - Loaded weights file from disk, setting weights to model.\u001b[0m\n",
      "\u001b[32m[2025-06-03 15:12:41,664] [    INFO]\u001b[0m - All model checkpoint weights were used when initializing ErnieMModel.\n",
      "\u001b[0m\n",
      "\u001b[32m[2025-06-03 15:12:41,665] [    INFO]\u001b[0m - All the weights of ErnieMModel were initialized from the model checkpoint at ernie-m-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ErnieMModel for predictions without further training.\u001b[0m\n",
      "\u001b[32m[2025-06-03 15:12:42,377] [    INFO]\u001b[0m - tokenizer config file saved in /root/.paddlenlp/models/ernie-m-base/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2025-06-03 15:12:42,379] [    INFO]\u001b[0m - Special tokens file saved in /root/.paddlenlp/models/ernie-m-base/special_tokens_map.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55920 5592\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1:   0%|          | 0/5592 [00:00<?, ?it/s]W0603 15:12:42.836725  3572 gpu_resources.cc:306] WARNING: device: 0. The installed Paddle is compiled with CUDNN 8.9, but CUDNN version in your machine is 8.9, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\n",
      "Training Epoch 1: 100%|█████████▉| 5591/5592 [07:30<00:00, 12.08it/s, loss=0.1949, acc=0.6440, step=5592]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.50273, acc: 0.79985, f1: 0.75351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 5592/5592 [07:36<00:00, 12.24it/s, loss=0.1949, acc=0.6440, step=5592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 5592 | F1: 0.7535 (updated)\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|█████████▉| 5591/5592 [07:15<00:00, 14.05it/s, loss=0.1171, acc=0.8259, step=11184]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.34302, acc: 0.87930, f1: 0.85989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 5592/5592 [07:34<00:00, 12.30it/s, loss=0.1171, acc=0.8259, step=11184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 11184 | F1: 0.8599 (updated)\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|█████████▉| 5590/5592 [07:28<00:00, 10.77it/s, loss=0.1041, acc=0.8780, step=16776]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.27895, acc: 0.90069, f1: 0.88582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 5592/5592 [07:38<00:00,  3.07s/it, loss=0.1041, acc=0.8780, step=16776]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 16776 | F1: 0.8858 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 5592/5592 [07:38<00:00, 12.19it/s, loss=0.1041, acc=0.8780, step=16776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|█████████▉| 5591/5592 [07:30<00:00, 13.07it/s, loss=0.0941, acc=0.8967, step=22368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.25271, acc: 0.91291, f1: 0.90179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 5592/5592 [07:37<00:00,  3.56s/it, loss=0.0941, acc=0.8967, step=22368]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 22368 | F1: 0.9018 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 5592/5592 [07:38<00:00, 12.20it/s, loss=0.0941, acc=0.8967, step=22368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|█████████▉| 5591/5592 [07:32<00:00, 12.30it/s, loss=0.0118, acc=0.9151, step=27960]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.22753, acc: 0.91597, f1: 0.90503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 5592/5592 [07:37<00:00,  3.73s/it, loss=0.0118, acc=0.9151, step=27960]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 27960 | F1: 0.9050 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 5592/5592 [07:38<00:00, 12.21it/s, loss=0.0118, acc=0.9151, step=27960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|█████████▉| 5590/5592 [07:34<00:00, 12.90it/s, loss=0.4126, acc=0.9298, step=33552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.23047, acc: 0.91902, f1: 0.90880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 5592/5592 [07:38<00:00,  3.03s/it, loss=0.4126, acc=0.9298, step=33552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 33552 | F1: 0.9088 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 5592/5592 [07:38<00:00, 12.19it/s, loss=0.4126, acc=0.9298, step=33552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|█████████▉| 5591/5592 [07:17<00:00, 13.61it/s, loss=0.0101, acc=0.9376, step=39144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.22951, acc: 0.91902, f1: 0.90933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 5592/5592 [07:37<00:00,  3.55s/it, loss=0.0101, acc=0.9376, step=39144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 39144 | F1: 0.9093 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 5592/5592 [07:37<00:00, 12.21it/s, loss=0.0101, acc=0.9376, step=39144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|█████████▉| 5591/5592 [07:20<00:00, 13.92it/s, loss=0.0136, acc=0.9445, step=44736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.22480, acc: 0.92437, f1: 0.91381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 5592/5592 [07:39<00:00,  3.45s/it, loss=0.0136, acc=0.9445, step=44736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 44736 | F1: 0.9138 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 5592/5592 [07:40<00:00, 12.16it/s, loss=0.0136, acc=0.9445, step=44736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|█████████▉| 5591/5592 [07:28<00:00, 12.76it/s, loss=0.0515, acc=0.9481, step=50328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.21813, acc: 0.92513, f1: 0.91495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 5592/5592 [07:38<00:00,  3.71s/it, loss=0.0515, acc=0.9481, step=50328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BEST] Step 50328 | F1: 0.9149 (updated)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 5592/5592 [07:39<00:00, 12.16it/s, loss=0.0515, acc=0.9481, step=50328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 5592/5592 [07:39<00:00,  3.03s/it, loss=0.0181, acc=0.9542, step=55920]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.21909, acc: 0.92437, f1: 0.91468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|██████████| 5592/5592 [07:39<00:00, 12.16it/s, loss=0.0181, acc=0.9542, step=55920]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1129/1129 [00:22<00:00, 49.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import time\n",
    "import os \n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "import gc\n",
    "import paddle\n",
    "from paddlenlp.datasets import load_dataset\n",
    "import paddle.nn.functional as F\n",
    "import paddle.nn as nn\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "import pandas as pd\n",
    "from paddle.vision import transforms as T\n",
    "from paddle.io import Dataset\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from PIL import Image\n",
    "import os\n",
    "import imghdr\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 更通用的写法，兼容 Jupyter 和脚本运行\n",
    "try:\n",
    "    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "except NameError:\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "dataset_dir = os.path.join(base_dir, 'autodl-tmp/queries_dataset_merge')\n",
    "\n",
    "paddle.set_device('gpu')  # 如果没 GPU，可以改为 'cpu'\n",
    "\n",
    "#读取数据\n",
    "import json\n",
    "data_items_train = json.load(open(os.path.join(dataset_dir, 'dataset_items_train.json'), encoding='utf-8'))\n",
    "data_items_val = json.load(open(os.path.join(dataset_dir, 'dataset_items_val.json'), encoding='utf-8'))\n",
    "data_items_test = json.load(open(os.path.join(dataset_dir, 'dataset_items_test.json'), encoding='utf-8'))\n",
    "\n",
    "\n",
    "#读取数据中的每一个样本：图像img、文本caption、\n",
    "#对应的img_html_news、inverse_search为支持图像img和文本caption的证据材料\n",
    "def process_string(input_str):\n",
    "    input_str = input_str.replace('&#39;', ' ')\n",
    "    input_str = input_str.replace('<b>', '')\n",
    "    input_str = input_str.replace('</b>', '')\n",
    "    # input_str = unidecode(input_str)\n",
    "    return input_str\n",
    "\n",
    "\n",
    "class FeatureCachedNewsContextDataset(Dataset):\n",
    "    def __init__(self, context_data_items_dict, queries_root_dir, split, resnet_model, cache_dir='cache_features'):\n",
    "        self.cache_path = os.path.join(cache_dir, f'{split}_features_cached.pkl')\n",
    "        self.split = split\n",
    "        self.resnet = resnet_model\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "        if os.path.exists(self.cache_path):\n",
    "            print(f\"[INFO] Loading cached features from {self.cache_path}\")\n",
    "            with open(self.cache_path, 'rb') as f:\n",
    "                self.samples = pickle.load(f)\n",
    "        else:\n",
    "            print(f\"[INFO] Creating cache with CNN features for {split} set...\")\n",
    "            self.samples = self.preprocess_and_cache(context_data_items_dict, queries_root_dir)\n",
    "            with open(self.cache_path, 'wb') as f:\n",
    "                pickle.dump(self.samples, f)\n",
    "            print(f\"[INFO] Cached features saved to {self.cache_path}\")\n",
    "\n",
    "    def preprocess_and_cache(self, data_dict, queries_root_dir):\n",
    "        from PIL import Image\n",
    "        import imghdr\n",
    "        from paddle.vision import transforms as T\n",
    "\n",
    "        transform = T.Compose([\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        def load_image(image_path):\n",
    "            try:\n",
    "                if imghdr.what(image_path) == 'gif':\n",
    "                    with open(image_path, 'rb') as f:\n",
    "                        img = Image.open(f).convert('RGB')\n",
    "                else:\n",
    "                    with open(image_path, 'rb') as f:\n",
    "                        img = Image.open(f).convert('RGB')\n",
    "                return transform(img)\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        def process_string(text):\n",
    "            return text.replace('&#39;', ' ').replace('<b>', '').replace('</b>', '')\n",
    "\n",
    "        def extract_captions(inv_dict, direct_dict):\n",
    "            captions = []\n",
    "            for key in ['all_fully_matched_captions', 'all_partially_matched_captions']:\n",
    "                for page in inv_dict.get(key, []):\n",
    "                    if 'title' in page:\n",
    "                        captions.append(process_string(page['title']))\n",
    "                    if 'caption' in page:\n",
    "                        for val in page['caption'].values():\n",
    "                            captions.append(process_string(val))\n",
    "            for key in ['images_with_captions', 'images_with_caption_matched_tags', 'images_with_no_captions']:\n",
    "                for page in direct_dict.get(key, []):\n",
    "                    if 'page_title' in page:\n",
    "                        captions.append(process_string(page['page_title']))\n",
    "                    if 'caption' in page:\n",
    "                        for val in page['caption'].values():\n",
    "                            captions.append(process_string(val))\n",
    "            return list(set(captions))\n",
    "\n",
    "        MAX_IMG_PER_SAMPLE = 100\n",
    "        samples = []\n",
    "\n",
    "        for key in tqdm(data_dict, desc=f\"Processing {self.split} with features\"):\n",
    "            item = data_dict[key]\n",
    "            try:\n",
    "                qimg_path = os.path.join(queries_root_dir, item['image_path'])\n",
    "                qimg_tensor = load_image(qimg_path)\n",
    "                if qimg_tensor is None:\n",
    "                    continue\n",
    "                qImg_feature = self.resnet(qimg_tensor.unsqueeze(0)).detach().cpu().squeeze(0).numpy()\n",
    "\n",
    "                direct_path = os.path.join(queries_root_dir, item['direct_path'])\n",
    "                inverse_path = os.path.join(queries_root_dir, item['inv_path'])\n",
    "\n",
    "                with open(os.path.join(direct_path, 'direct_annotation.json'), encoding='utf-8') as f:\n",
    "                    direct_dict = json.load(f)\n",
    "                with open(os.path.join(inverse_path, 'inverse_annotation.json'), encoding='utf-8') as f:\n",
    "                    inv_dict = json.load(f)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {e}, skipping {key}\")\n",
    "                continue\n",
    "\n",
    "            evidence_features = []\n",
    "            for key1 in ['images_with_captions', 'images_with_no_captions', 'images_with_caption_matched_tags']:\n",
    "                pages = direct_dict.get(key1, [])\n",
    "                for i, page in enumerate(pages):\n",
    "                    if i >= MAX_IMG_PER_SAMPLE:\n",
    "                        break\n",
    "                    img_path = os.path.join(direct_path, page['image_path'].split('/')[-1])\n",
    "                    img_tensor = load_image(img_path)\n",
    "                    if img_tensor is not None:\n",
    "                        img_feature = self.resnet(img_tensor.unsqueeze(0)).detach().cpu().squeeze(0).numpy()\n",
    "                        evidence_features.append(img_feature)\n",
    "\n",
    "            if len(evidence_features) == 0:\n",
    "                continue\n",
    "\n",
    "            captions = extract_captions(inv_dict, direct_dict)\n",
    "            sample = {\n",
    "                'qImg_feature': qImg_feature,\n",
    "                'qCap': item['caption'],\n",
    "                'imgs_features': evidence_features,\n",
    "                'caption': captions\n",
    "            }\n",
    "            if self.split != 'test':\n",
    "                sample['label'] = int(item['label'])\n",
    "\n",
    "            samples.append(sample)\n",
    "\n",
    "            # 显存清理\n",
    "            del qImg_feature, evidence_features, img_tensor, qimg_tensor\n",
    "            gc.collect()\n",
    "            paddle.device.cuda.empty_cache()\n",
    "\n",
    "        print(f\"[INFO] Cached {len(samples)} samples for {self.split}\")\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        if self.split != 'test':\n",
    "            return sample, len(sample['caption']), len(sample['imgs_features'])\n",
    "        else:\n",
    "            return sample, len(sample['caption']), len(sample['imgs_features'])\n",
    "\n",
    "from paddle.vision import models\n",
    "from paddle import nn\n",
    "import paddle\n",
    "class EncoderCNN(nn.Layer):\n",
    "    def __init__(self, resnet_arch='resnet101'):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        if resnet_arch == 'resnet101':\n",
    "            resnet = models.resnet101(pretrained=True)\n",
    "        elif resnet_arch == 'resnet50':\n",
    "            resnet = models.resnet50(pretrained=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported ResNet arch: {resnet_arch}\")\n",
    "\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2D((1, 1))\n",
    "\n",
    "    def forward(self, images, features='pool'):\n",
    "        out = self.resnet(images)\n",
    "        if features == 'pool':\n",
    "            out = self.adaptive_pool(out)\n",
    "            out = paddle.reshape(out, (out.shape[0], out.shape[1]))\n",
    "        return out\n",
    "\n",
    "#### load Datasets ####\n",
    "resnet = EncoderCNN(resnet_arch='resnet50')\n",
    "resnet.eval()\n",
    "train_dataset = FeatureCachedNewsContextDataset(data_items_train, dataset_dir, 'train', resnet)\n",
    "val_dataset = FeatureCachedNewsContextDataset(data_items_val, dataset_dir, 'val', resnet)\n",
    "test_dataset = FeatureCachedNewsContextDataset(data_items_test, dataset_dir, 'test', resnet)\n",
    "print(f\"train_dataset total samples: {len(train_dataset)}\")\n",
    "print(f\"val_dataset total samples: {len(val_dataset)}\")\n",
    "print(f\"test_dataset total samples: {len(test_dataset)}\")\n",
    "\n",
    "# 打印数据\n",
    "for step, batch in enumerate(test_dataset, start=1):\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "def collate_context_cached_train(batch):\n",
    "    samples = [item[0] for item in batch]\n",
    "    max_caps = max([item[1] for item in batch])\n",
    "    max_imgs = max([item[2] for item in batch])\n",
    "\n",
    "    qCap_batch, qImg_feature_batch, caps_batch, imgs_feature_batch, labels = [], [], [], [], []\n",
    "\n",
    "    for sample in samples:\n",
    "        caps = sample['caption'] + [\"\"] * (max_caps - len(sample['caption']))\n",
    "        caps_batch.append(caps)\n",
    "\n",
    "        imgs = sample['imgs_features']\n",
    "        imgs = [paddle.to_tensor(img, dtype='float32') for img in imgs]\n",
    "        pad = [paddle.zeros_like(imgs[0]) for _ in range(max_imgs - len(imgs))]\n",
    "        imgs_padded = imgs + pad\n",
    "        imgs_feature_batch.append(paddle.stack(imgs_padded))\n",
    "\n",
    "        qCap_batch.append(sample['qCap'])\n",
    "        qImg_feature_batch.append(paddle.to_tensor(sample['qImg_feature'], dtype='float32'))\n",
    "\n",
    "        labels.append(paddle.to_tensor(sample['label']))\n",
    "\n",
    "    qImg_feature_batch = paddle.stack(qImg_feature_batch, axis=0)\n",
    "    imgs_feature_batch = paddle.stack(imgs_feature_batch, axis=0)\n",
    "    labels = paddle.stack(labels)\n",
    "\n",
    "    return labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch\n",
    "\n",
    "\n",
    "def collate_context_cached_test(batch):\n",
    "    samples = [item[0] for item in batch]\n",
    "    max_caps = max([item[1] for item in batch])\n",
    "    max_imgs = max([item[2] for item in batch])\n",
    "\n",
    "    qCap_batch, qImg_feature_batch, caps_batch, imgs_feature_batch = [], [], [], []\n",
    "\n",
    "    for sample in samples:\n",
    "        caps = sample['caption'] + [\"\"] * (max_caps - len(sample['caption']))\n",
    "        caps_batch.append(caps)\n",
    "\n",
    "        imgs = sample['imgs_features']\n",
    "        imgs = [paddle.to_tensor(img, dtype='float32') for img in imgs]\n",
    "        pad = [paddle.zeros_like(imgs[0]) for _ in range(max_imgs - len(imgs))]\n",
    "        imgs_padded = imgs + pad\n",
    "        imgs_feature_batch.append(paddle.stack(imgs_padded))\n",
    "\n",
    "        qCap_batch.append(sample['qCap'])\n",
    "        qImg_feature_batch.append(paddle.to_tensor(sample['qImg_feature'], dtype='float32'))\n",
    "\n",
    "    qImg_feature_batch = paddle.stack(qImg_feature_batch, axis=0)\n",
    "    imgs_feature_batch = paddle.stack(imgs_feature_batch, axis=0)\n",
    "\n",
    "    return caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch\n",
    "\n",
    "\n",
    "\n",
    "# load DataLoader\n",
    "from paddle.io import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True,\n",
    "                              collate_fn=collate_context_cached_train, return_list=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False,\n",
    "                            collate_fn=collate_context_cached_train, return_list=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False,\n",
    "                             collate_fn=collate_context_cached_test, return_list=True, num_workers=2)\n",
    "\n",
    "# 打印数据\n",
    "for step, batch in enumerate(train_dataloader, start=1):\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "#模型构建\n",
    "from paddle.vision import models\n",
    "import paddle\n",
    "from paddlenlp.transformers import ErnieMModel,ErnieMTokenizer\n",
    "from paddle.nn import functional as F\n",
    "from paddle import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "class EncoderCNN(nn.Layer):\n",
    "    def __init__(self, resnet_arch = 'resnet101'):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        if resnet_arch == 'resnet101':\n",
    "            resnet = models.resnet101(pretrained=True)\n",
    "        modules = list(resnet.children())[:-2]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2D((1, 1))\n",
    "    def forward(self, images, features='pool'):\n",
    "        out = self.resnet(images)\n",
    "        if features == 'pool':\n",
    "            out = self.adaptive_pool(out)\n",
    "            out = paddle.reshape(out, (out.shape[0],out.shape[1]))\n",
    "        return out\n",
    "\n",
    "\n",
    "class NetWork(nn.Layer):\n",
    "    def __init__(self, mode):\n",
    "        super(NetWork, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.ernie = ErnieMModel.from_pretrained('ernie-m-base')\n",
    "        self.tokenizer = ErnieMTokenizer.from_pretrained('ernie-m-base')\n",
    "        self.attention_text = nn.MultiHeadAttention(embed_dim=768, num_heads=16)\n",
    "        self.attention_image = nn.MultiHeadAttention(embed_dim=2048, num_heads=16)\n",
    "\n",
    "        if self.mode == 'text':\n",
    "            self.classifier = nn.Linear(768, 3)\n",
    "        else:\n",
    "            self.classifier1 = nn.Linear(2 * (768 + 2048), 1024)\n",
    "            self.classifier2 = nn.Linear(1024, 3)\n",
    "\n",
    "    def forward(self, qCap, qImg_feature, caps, imgs_features):\n",
    "        # Encode qCap\n",
    "        encode_dict_qcap = self.tokenizer(text=qCap, max_length=128, truncation=True, padding='max_length')\n",
    "        input_ids_qcap = paddle.to_tensor(encode_dict_qcap['input_ids'])\n",
    "        qcap_feature, _ = self.ernie(input_ids_qcap)\n",
    "\n",
    "        if self.mode == 'text':\n",
    "            logits = self.classifier(qcap_feature[:, 0, :])\n",
    "            return logits\n",
    "\n",
    "        # Encode all evidence captions\n",
    "        caps_feature = []\n",
    "        for caption_list in caps:\n",
    "            encode_dict_cap = self.tokenizer(text=caption_list, max_length=128, truncation=True, padding='max_length')\n",
    "            input_ids_caps = paddle.to_tensor(encode_dict_cap['input_ids'])\n",
    "            cap_feature, _ = self.ernie(input_ids_caps)\n",
    "            cap_feature = cap_feature.mean(axis=1)  # mean pooling over all captions\n",
    "            caps_feature.append(cap_feature)\n",
    "        caps_feature = paddle.stack(caps_feature, axis=0)\n",
    "\n",
    "        # Attention between qcap and caps\n",
    "        caps_feature = self.attention_text(qcap_feature, caps_feature, caps_feature)\n",
    "\n",
    "        # Attention over image features\n",
    "        # imgs_features = paddle.stack(imgs_features, axis=0)  # [B, N, 2048]\n",
    "        qImg_feature = qImg_feature.unsqueeze(1)  # [B, 1, 2048]\n",
    "        imgs_features = self.attention_image(qImg_feature, imgs_features, imgs_features)\n",
    "\n",
    "        # Concatenate and classify\n",
    "        feature = paddle.concat(\n",
    "            [qcap_feature[:, 0, :], caps_feature[:, 0, :], qImg_feature.squeeze(1), imgs_features.squeeze(1)],\n",
    "            axis=-1)\n",
    "        logits = self.classifier1(feature)\n",
    "        logits = self.classifier2(logits)\n",
    "        return logits\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in data_loader:\n",
    "        labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "        logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                       caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        preds = paddle.argmax(F.softmax(logits, axis=-1), axis=1)\n",
    "        all_preds.extend(preds.numpy().tolist())\n",
    "        all_labels.extend(labels.numpy().tolist())\n",
    "\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "\n",
    "    acc = metric.accumulate()\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')  # 或 'weighted' 视情况而定\n",
    "    print(f\"Eval loss: {np.mean(losses):.5f}, acc: {acc:.5f}, f1: {f1:.5f}\")\n",
    "    model.train()\n",
    "    metric.reset()\n",
    "    return np.mean(losses), acc, f1\n",
    "\n",
    "\n",
    "# 声明模型\n",
    "model = NetWork(\"image\")\n",
    "#print(model)\n",
    "\n",
    "epochs = 10\n",
    "num_training_steps = len(train_dataloader) * epochs\n",
    "warmup_steps = int(num_training_steps*0.1)\n",
    "print(num_training_steps,warmup_steps)\n",
    "\n",
    "# 定义 learning_rate_scheduler，负责在训练过程中对 lr 进行调度\n",
    "lr_scheduler = LinearDecayWithWarmup(1e-6, num_training_steps, warmup_steps)\n",
    "# 训练结束后，存储模型参数\n",
    "save_dir =\"checkpoint/\"\n",
    "best_dir = \"best_model\"\n",
    "# 创建保存的文件夹\n",
    "os.makedirs(save_dir,exist_ok=True)\n",
    "os.makedirs(best_dir,exist_ok=True)\n",
    "\n",
    "decay_params = [\n",
    "    p.name for n, p in model.named_parameters()\n",
    "    if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "]\n",
    "\n",
    "# 定义 Optimizer\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=1.2e-4,\n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "# 交叉熵损失\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "\n",
    "# 评估的时候采用准确率指标\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "if paddle.is_compiled_with_cuda():\n",
    "    paddle.set_device('gpu')\n",
    "else:\n",
    "    paddle.set_device('cpu')\n",
    "\n",
    "# 定义训练\n",
    "def do_train(model, criterion, metric, val_dataloader, train_dataloader, optimizer, lr_scheduler,\n",
    "             save_dir=\"checkpoint\", best_dir=\"best_model\", epochs=10):\n",
    "\n",
    "    global_step = 0\n",
    "    best_f1 = 0.0\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(best_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
    "        model.train()\n",
    "        train_loader_progress = tqdm(train_dataloader, desc=f\"Training Epoch {epoch}\", leave=True)\n",
    "\n",
    "        for step, batch in enumerate(train_loader_progress, start=1):\n",
    "            labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "\n",
    "            logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                           caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            correct = metric.compute(logits, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "\n",
    "            global_step += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "\n",
    "            train_loader_progress.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"acc\": f\"{acc:.4f}\",\n",
    "                \"step\": global_step\n",
    "            })\n",
    "\n",
    "            if global_step % len(train_dataloader) == 0:\n",
    "                eval_loss, eval_acc, eval_f1 = evaluate(model, criterion, metric, val_dataloader)\n",
    "\n",
    "                if eval_f1 > best_f1:\n",
    "                    best_f1 = eval_f1\n",
    "                    best_model_path = os.path.join(best_dir, 'model_bestinitial.pdparams')\n",
    "                    paddle.save(model.state_dict(), best_model_path)\n",
    "                    print(f\"[BEST] Step {global_step} | F1: {eval_f1:.4f} (updated)\")\n",
    "\n",
    "\n",
    "do_train(\n",
    "    model, criterion, metric, val_dataloader, train_dataloader,\n",
    "    optimizer, lr_scheduler,\n",
    "    save_dir=\"checkpoint\", best_dir=\"best_model\", epochs=10\n",
    ")\n",
    "\n",
    "\n",
    "# 根据实际运行情况，更换加载的参数路径\n",
    "import os\n",
    "import paddle\n",
    "\n",
    "# 加载最优模型\n",
    "params_path = os.path.join(\"best_model\", \"model_bestinitial.pdparams\")\n",
    "if os.path.exists(params_path):\n",
    "    model.set_dict(paddle.load(params_path))\n",
    "    print(\"Loaded best model.\")\n",
    "\n",
    "model.eval()\n",
    "results = []\n",
    "for batch in tqdm(test_dataloader, desc=\"Predicting\"):\n",
    "    caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "    logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                   caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "    preds = paddle.argmax(F.softmax(logits, axis=-1), axis=1).numpy()\n",
    "    results.extend(preds.tolist())\n",
    "\n",
    "# 保存\n",
    "pd.DataFrame({\"id\": range(len(results)), \"label\": results}).to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c15c3c05-9e8c-486f-a076-0ff2e710529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 655/655 [01:36<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.21813, Accuracy: 0.92513, F1 Score (macro): 0.91495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 验证函数（带F1）\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "        labels, caps_batch, imgs_feature_batch, qCap_batch, qImg_feature_batch = batch\n",
    "        logits = model(qCap=qCap_batch, qImg_feature=qImg_feature_batch,\n",
    "                       caps=caps_batch, imgs_features=imgs_feature_batch)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        preds = paddle.argmax(F.softmax(logits, axis=-1), axis=1)\n",
    "        all_preds.extend(preds.numpy().tolist())\n",
    "        all_labels.extend(labels.numpy().tolist())\n",
    "\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "\n",
    "        gc.collect()\n",
    "        paddle.device.cuda.empty_cache()\n",
    "\n",
    "    acc = metric.accumulate()\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(\"Eval Loss: {:.5f}, Accuracy: {:.5f}, F1 Score (macro): {:.5f}\".format(np.mean(losses), acc, f1))\n",
    "    return np.mean(losses), acc, f1\n",
    "\n",
    "# 加载模型参数\n",
    "params_path = os.path.join(\"best_model\", \"model_bestinitial.pdparams\")\n",
    "if os.path.exists(params_path):\n",
    "    model.set_dict(paddle.load(params_path))\n",
    "    print(\"Loaded best model.\")\n",
    "else:\n",
    "    print(\"Best model file not found!\")\n",
    "\n",
    "# 损失函数和评估指标\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "# 执行评估\n",
    "eval_loss, eval_acc, eval_f1 = evaluate(model, criterion, metric, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11677d-1d31-43ea-ab2c-2cee0799d0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle1",
   "language": "python",
   "name": "paddle1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
